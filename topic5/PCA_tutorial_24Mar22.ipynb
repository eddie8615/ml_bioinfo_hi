{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <U> Practical Tutorial PCA</U>:\n",
    "\n",
    "- We are going to use Principal Component Analysis to reduce the dimensionality of a dataset. \n",
    "\n",
    "\n",
    "- Remember, three vital packages will be used throughout: \n",
    "    - Pandas for data wrangling\n",
    "    - Matplotlib for plotting\n",
    "    - Sklean for machine learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before you begin\n",
    "\n",
    "- Make sure you know the full path to tumour_gene_data.csv and tumour_gene_labels.csv for your own computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the data\n",
    "tumour_gene_data = pd.read_csv('/path/to/data/tumour_gene_data.csv', index_col=0)\n",
    "tumour_labels = pd.read_csv('/path/to/data/tumour_gene_labels.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When you've uploaded the data, quickly check the dimensionality of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dimensionality\n",
    "tumour_gene_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As you can see we have 277 instances and 20531 features.\n",
    "##### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <U> Part 1: Dimensionality reduction with PCA</U>:\n",
    "\n",
    "- There are several ways to reduce the number of features in a dataset. One tool that is often used for highly dimensional datasets is Principal Comonponenet Analysis (PCA). Here we will apply PCA to our gene data.\n",
    "- First we should to scale our data to mean = 0 and variance = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Scale the data using the sklearn StandardScaler() function and run a PCA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here!\n",
    "tumour_gene_data_scaled = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now lets apply PCA to our dataset to return a dataset containing the PCA components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the PCA model with the desired number of components\n",
    "pca = PCA(n_components=100)\n",
    "\n",
    "# Apply PCA to the data and return the computed principal components\n",
    "tumour_gene_data_PCA = pca.fit_transform(tumour_gene_data_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now let's check the dimensionality of the PCA transformed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here!\n",
    "# Check the PCA data dimensionality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After applying PCA it is important to check how much variance is being explained by our prinicipal component loadings.\n",
    "- Let's have a look at this with a simple bar chart and the sum of variance explained across all principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl_var = pca.explained_variance_ratio_\n",
    "plt.bar(list(range(100)), expl_var)\n",
    "print('Total variance explained = ', sum(expl_var)*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color='blue'>Question: Why is it important to scale our data before applying PCA?</font>\n",
    "\n",
    "##### <font color='blue'>Question: What does the distribution of principal components show?</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Change the number of components included in the PCA and see how this changes the amount of variance explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit code here!\n",
    "# Run a PCA with a different number of components and return the total variance explained (try between 2 and 300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color='blue'>Question: how many principal componenets can you create from the data?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Having the data in lower dimensional space means we can plot it in 2d. Take the first two components of any PCA reduced dataset and see how they seperate into the two types of tumour with a scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here! \n",
    "# Hint, here is a vector of colours that match the tumour labels\n",
    "label_colours = tumour_labels.Class.map({'PRAD': 'red', 'LUAD':'blue'})\n",
    "\n",
    "# Create a 2d scatterplot with one principal component on each axis and points coloured according\n",
    "# tumour labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color='blue'>Question: do you think a classifier based on the first two components would work well at predicting the tumour labels?</font>\n",
    "##### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <U> Part 2: Classification and Dimensionality</U>:\n",
    "\n",
    "### Task 1: Let's see how a simple classifer performs on our data \n",
    "\n",
    "- Split the data into training (N = 177) and test data (N = 100). \n",
    "- Don't worry about cross validation for this practical.\n",
    "- Train the SVM classifier on the training data and use it to predict tumour type labels in the unseen test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test samples\n",
    "train = tumour_gene_data.iloc[:177,:]\n",
    "train_labels = tumour_labels.iloc[:177].Class\n",
    "\n",
    "test = tumour_gene_data.iloc[177:,:]\n",
    "test_labels = tumour_labels.iloc[177:].Class\n",
    "\n",
    "# Your code here!\n",
    "# Run an SVM classifier on the training data and predict the test data labels\n",
    "\n",
    "# Print the prediction accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Your SVM prediction model should work perfectly! But what happens if we drastically reduce our training sample size? (Next task).\n",
    "\n",
    "### Task 2: Repeat the SVM classifier above with only 10 samples in the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here!\n",
    "# Split the data into training and test samples, with only the first 10 samples in the training dataset\n",
    "\n",
    "# Run an SVM classifier on the training data and predict the test data labels\n",
    "\n",
    "# Print the prediction accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color='blue'>Question: How does the classfier perform when we have less samples in the training dataset?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Now use PCA to reduce the dimensionality of the dataset and apply another SVM classifier.\n",
    "\n",
    "- Keep the same number of datapoints in the training dataset (N = 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here!\n",
    "# Run a PCA on the data with a low number of componenets (try a few examples between 2 and 20)\n",
    "\n",
    "# Split data into training and test samples\n",
    "\n",
    "# Run an SVM classifier on the training data and predict the test data labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color='blue'>Question: Why might sample size and number of features change the prediction accuracy of the unseen data?</font>\n",
    "##### \n",
    "##### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <U> Optional bonus excercise</U>:\n",
    "\n",
    "### Pick two (or more) clustering techniques and use the adjusted Rand score to see how well the clustering solution matches the original labels\n",
    "\n",
    "- A list of clustering methods can be found here: https://scikit-learn.org/stable/modules/clustering.html\n",
    "- The adjusted Rand Score give us a measure of similarity between two clustering solutions: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here!\n",
    "# Import packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here!\n",
    "# For the adjusted Rand score the labels need to be integers. Replace the 'LUAD' and 'PRAD' labels with 0 and 1\n",
    "# in the tumour_labels file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here!\n",
    "# Cluster the tumour_gene_data using two (or more) clustering algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here!\n",
    "# Use the adjusted Rand score to compare clustering solutions to the original labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <font color='blue'>Question: What does this tell us about our dataset?</font>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
