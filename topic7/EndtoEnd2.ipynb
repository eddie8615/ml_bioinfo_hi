{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> End-to-end Example of a Machine Learning Pipeline for Imbalanced Data - Part II </h1>\n",
    "\n",
    "Now that we have imputed and selected a 'potential' model, let's build on it using the properties of our data. \n",
    "\n",
    "<h1>Table of contents</h1>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "    <ol>\n",
    "        <li><a href=\"#read\">Reading and examining the data</a></li>\n",
    "        <li><a href=\"#imbalance\">'Scope out' different techniques for handling imbalance </a></li>\n",
    "        <li><a href=\"#tune\">Tune the hyperparameters for the selected approach</a></li>\n",
    "        <li><a href=\"#validate\">Cross-validate to establish confidence</a></li>\n",
    "    </ol>\n",
    "</div>\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"read\">Reading and examining the data</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path_to_file =\"/Users/babylon/Documents/Teaching/ML/ML2022/Week2/FavouriteData.csv\"\n",
    "pima_data = pd.read_csv(path_to_file, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double check that we have the scaled & imputed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.468243</td>\n",
       "      <td>0.862287</td>\n",
       "      <td>-0.032746</td>\n",
       "      <td>0.558557</td>\n",
       "      <td>-0.072061</td>\n",
       "      <td>0.165097</td>\n",
       "      <td>0.468492</td>\n",
       "      <td>1.425995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.087043</td>\n",
       "      <td>-1.202229</td>\n",
       "      <td>-0.517645</td>\n",
       "      <td>-0.014657</td>\n",
       "      <td>-0.893978</td>\n",
       "      <td>-0.846404</td>\n",
       "      <td>-0.365061</td>\n",
       "      <td>-0.190672</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.090358</td>\n",
       "      <td>2.009241</td>\n",
       "      <td>-0.679278</td>\n",
       "      <td>0.797396</td>\n",
       "      <td>0.606548</td>\n",
       "      <td>-1.323254</td>\n",
       "      <td>0.604397</td>\n",
       "      <td>-0.105584</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.087043</td>\n",
       "      <td>-1.071148</td>\n",
       "      <td>-0.517645</td>\n",
       "      <td>-0.587871</td>\n",
       "      <td>-0.518847</td>\n",
       "      <td>-0.629654</td>\n",
       "      <td>-0.920763</td>\n",
       "      <td>-1.041549</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.775986</td>\n",
       "      <td>0.501816</td>\n",
       "      <td>-2.618874</td>\n",
       "      <td>0.558557</td>\n",
       "      <td>0.104968</td>\n",
       "      <td>1.537847</td>\n",
       "      <td>5.484909</td>\n",
       "      <td>-0.020496</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin       BMI  \\\n",
       "0     0.468243  0.862287      -0.032746       0.558557 -0.072061  0.165097   \n",
       "1    -1.087043 -1.202229      -0.517645      -0.014657 -0.893978 -0.846404   \n",
       "2     1.090358  2.009241      -0.679278       0.797396  0.606548 -1.323254   \n",
       "3    -1.087043 -1.071148      -0.517645      -0.587871 -0.518847 -0.629654   \n",
       "4    -0.775986  0.501816      -2.618874       0.558557  0.104968  1.537847   \n",
       "\n",
       "   DiabetesPedigreeFunction       Age  Outcome  \n",
       "0                  0.468492  1.425995        1  \n",
       "1                 -0.365061 -0.190672        0  \n",
       "2                  0.604397 -0.105584        1  \n",
       "3                 -0.920763 -1.041549        0  \n",
       "4                  5.484909 -0.020496        1  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>7.680000e+02</td>\n",
       "      <td>7.680000e+02</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.028112</td>\n",
       "      <td>-0.003560</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>-0.009868</td>\n",
       "      <td>-0.023962</td>\n",
       "      <td>-0.000401</td>\n",
       "      <td>2.451743e-16</td>\n",
       "      <td>1.838807e-16</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.958000</td>\n",
       "      <td>0.999097</td>\n",
       "      <td>0.990833</td>\n",
       "      <td>0.935252</td>\n",
       "      <td>0.880537</td>\n",
       "      <td>0.995225</td>\n",
       "      <td>1.000652e+00</td>\n",
       "      <td>1.000652e+00</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.087043</td>\n",
       "      <td>-2.545803</td>\n",
       "      <td>-3.911938</td>\n",
       "      <td>-2.116442</td>\n",
       "      <td>-1.193241</td>\n",
       "      <td>-2.060204</td>\n",
       "      <td>-1.189553e+00</td>\n",
       "      <td>-1.041549e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.775986</td>\n",
       "      <td>-0.743447</td>\n",
       "      <td>-0.679278</td>\n",
       "      <td>-0.683407</td>\n",
       "      <td>-0.613684</td>\n",
       "      <td>-0.716354</td>\n",
       "      <td>-6.889685e-01</td>\n",
       "      <td>-7.862862e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.153872</td>\n",
       "      <td>-0.153586</td>\n",
       "      <td>-0.032746</td>\n",
       "      <td>-0.014657</td>\n",
       "      <td>-0.249089</td>\n",
       "      <td>-0.022754</td>\n",
       "      <td>-3.001282e-01</td>\n",
       "      <td>-3.608474e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.468243</td>\n",
       "      <td>0.608319</td>\n",
       "      <td>0.613787</td>\n",
       "      <td>0.618267</td>\n",
       "      <td>0.290426</td>\n",
       "      <td>0.598597</td>\n",
       "      <td>4.662269e-01</td>\n",
       "      <td>6.602056e-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.889873</td>\n",
       "      <td>2.533562</td>\n",
       "      <td>4.008080</td>\n",
       "      <td>6.672840</td>\n",
       "      <td>5.820456</td>\n",
       "      <td>5.005848</td>\n",
       "      <td>5.883565e+00</td>\n",
       "      <td>4.063716e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean     -0.028112   -0.003560      -0.000072      -0.009868   -0.023962   \n",
       "std       0.958000    0.999097       0.990833       0.935252    0.880537   \n",
       "min      -1.087043   -2.545803      -3.911938      -2.116442   -1.193241   \n",
       "25%      -0.775986   -0.743447      -0.679278      -0.683407   -0.613684   \n",
       "50%      -0.153872   -0.153586      -0.032746      -0.014657   -0.249089   \n",
       "75%       0.468243    0.608319       0.613787       0.618267    0.290426   \n",
       "max       3.889873    2.533562       4.008080       6.672840    5.820456   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction           Age     Outcome  \n",
       "count  768.000000              7.680000e+02  7.680000e+02  768.000000  \n",
       "mean    -0.000401              2.451743e-16  1.838807e-16    0.348958  \n",
       "std      0.995225              1.000652e+00  1.000652e+00    0.476951  \n",
       "min     -2.060204             -1.189553e+00 -1.041549e+00    0.000000  \n",
       "25%     -0.716354             -6.889685e-01 -7.862862e-01    0.000000  \n",
       "50%     -0.022754             -3.001282e-01 -3.608474e-01    0.000000  \n",
       "75%      0.598597              4.662269e-01  6.602056e-01    1.000000  \n",
       "max      5.005848              5.883565e+00  4.063716e+00    1.000000  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct X and y (I will call X, X_original as I will be updating it as the practical goes on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_original = pima_data[[\"Pregnancies\",\"Glucose\",\"BloodPressure\",\"SkinThickness\",\"Insulin\",\"BMI\",\"DiabetesPedigreeFunction\",\"Age\"]]\n",
    "y = pima_data[\"Outcome\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's examine the distribution of the outcome y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Your Task: </b>\n",
    "\n",
    "    - As in previous practicals, plot a pie chart to show the distribution of the outcome y. \n",
    "    - Guidance: \n",
    "        - y.value_count() gets you the total count of each possible y value. \n",
    "        - Here's an example from matplot lib to help you get started (if you don't want to look at previous practicals): \n",
    "            - Link: https://matplotlib.org/3.1.1/gallery/pie_and_polar_charts/pie_features.html\n",
    "            - You don't have to use explode or axes as the example does, because we're plotting a simple chart. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Your solution here ##\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that if you don't want to plot, you can always use counter to give you an idea as in below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 500, 1: 268})\n"
     ]
    }
   ],
   "source": [
    "##check the size of the data: \n",
    "from collections import Counter \n",
    "counter = Counter(y)\n",
    "print(counter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's also recap our favourite model from the previous practical \n",
    "- You can also save this model, more on this later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Classification report of RF using KNN Imputation : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82        99\n",
      "           1       0.68      0.69      0.68        55\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.75      0.75      0.75       154\n",
      "weighted avg       0.77      0.77      0.77       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_original, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "#Feed data into Random Forest Algorithm\n",
    "clf1 = RandomForestClassifier(random_state=42)\n",
    "clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "\n",
    "#Check performance\n",
    "print(\" Classification report of RF using KNN Imputation : \")\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"imbalance\">'Scope out' different techniques for handling imbalance </h2>\n",
    "\n",
    "- Now that we have: \n",
    "    1. A favourite classifer\n",
    "    2. Knowledge of the class imbalance\n",
    "- Let's try to improve our performance\n",
    "    - We care a lot about the minority class (Outcome = 1)\n",
    "    - Although the classifier's performance on the majority is okayish, we'd like to do better on the minority. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Approach 1: Weighted Classification </h3> \n",
    "\n",
    "- Idea: inform the classifer that different classes have different weights. \n",
    "    - The classifier then assigns different penalty rations for misclassifying the different classes. \n",
    "    - The idea/hope is that if the classifier is penalised more when misclassifying the minority class, it will work harder to avoid this penalty. \n",
    "    \n",
    "- But how do we choose the class weights?\n",
    "- The class weighing can be defined multiple ways; for example:\n",
    "\n",
    "    - Domain expertise, determined by talking to subject matter experts.\n",
    "    - Tuning, determined by a hyperparameter search such as a grid search.\n",
    "    - Heuristic, specified using a general best practice.\n",
    "\n",
    "- A best practice for using the class weighting is to use the inverse of the class distribution present in the training dataset.\n",
    "        -We can use the counter to establish the weights. \n",
    "            - As the counter shows (below), the number of samples in the minority class is approximately half of the number of samples in the majority class\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 401, 1: 213})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "counter = Counter(y_train)\n",
    "print(counter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With weighted classification, all you have to do is update the 'class_weight' parameter of the classifier. \n",
    "- class_weight takes a dictionary item, which we constructed based on the results of our counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Classification report of RF using KNN Imputation and class weights : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83        99\n",
      "           1       0.70      0.69      0.70        55\n",
      "\n",
      "    accuracy                           0.79       154\n",
      "   macro avg       0.77      0.76      0.77       154\n",
      "weighted avg       0.78      0.79      0.79       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#class weights\n",
    "weights = {0:0.5, 1:1.0}\n",
    "#train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_original, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "#Feed data into Random Forest Algorithm, note the class weight parameter!\n",
    "clf1 = RandomForestClassifier(class_weight = weights, random_state=42)\n",
    "clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "\n",
    "#Check performance\n",
    "print(\" Classification report of RF using KNN Imputation and class weights : \")\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A minor improvement - can we do better? let's try other approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Approach 2: SMOTE</h3> \n",
    "\n",
    "- There's a beautiful package called imblearn (imbalanced learning). \n",
    "- I highly encourage you to explore its documentation and get to know it better. \n",
    "- imblearn implements SMOTE (Synthetic Minority Oversampling TEchnique) is a very popular oversampling method that generates synthetic data from the minority class to match the number of samples in the majority class\n",
    "- imblearn documentation: https://imbalanced-learn.org/stable/\n",
    "- You may have to install it - as before, from your conda prompt: pip install imblear \n",
    "- I will help you in smoting your data, your job is to build the classifier and test it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 401, 1: 401})\n"
     ]
    }
   ],
   "source": [
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_original, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "oversample = SMOTE()\n",
    "X_train_smoted, y_train_smoted = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "#check the size of the data after SMOTing: \n",
    "counter = Counter(y_train_smoted)\n",
    "print(counter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They're equal :) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Your Task </b> \n",
    "- Build a new classifier, call it clf2\n",
    "- clf2 is trained on the smoted data (both X and y)\n",
    "- use it to predict y_pred for X_test\n",
    "- Output the classification report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Your solution here #####\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Approach 3: stratified sampling </h4> \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Classification report of RF using KNN Imputation and class weights : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.87      0.81       100\n",
      "           1       0.68      0.50      0.57        54\n",
      "\n",
      "    accuracy                           0.74       154\n",
      "   macro avg       0.72      0.69      0.69       154\n",
      "weighted avg       0.73      0.74      0.73       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#class weights\n",
    "weights = {0:0.5, 1:1.0}\n",
    "#train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_original, y, stratify=y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "#Feed data into Random Forest Algorithm, note the class weight parameter!\n",
    "clf3 = RandomForestClassifier(class_weight = weights, random_state=42)\n",
    "clf3.fit(X_train, y_train)\n",
    "y_pred = clf3.predict(X_test)\n",
    "\n",
    "#Check performance\n",
    "print(\" Classification report of RF using KNN Imputation and class weights : \")\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Approach 4: combine over and undersampling </h4>\n",
    "\n",
    "- The imblearn library has a really nice feature called 'pipelin' \n",
    "    - https://imbalanced-learn.org/stable/references/generated/imblearn.pipeline.Pipeline.html\n",
    "- Pipeline allows you to combine multiple steps (in our case: smoting the minority and undersampling the majority)\n",
    "- Go through the steps of this code to undersatnd what it's doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Classification report of RF with Over & Undersampling : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.76      0.79        99\n",
      "           1       0.62      0.73      0.67        55\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.74      0.73       154\n",
      "weighted avg       0.76      0.75      0.75       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_original, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "over = SMOTE(sampling_strategy='minority')\n",
    "under = RandomUnderSampler(sampling_strategy='majority')\n",
    "\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "X_overunder, y_overunder = pipeline.fit_resample(X_train, y_train)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from numpy import mean\n",
    "\n",
    "model.fit(X_overunder , y_overunder ) \n",
    "\n",
    "y_predicted = model.predict(X_test)\n",
    "print(\" Classification report of RF with Over & Undersampling : \")\n",
    "print(classification_report(y_test ,y_predicted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Which classifier performed better?\n",
    "- In my case, it depended on the run (I ran all multiple times), but:\n",
    "    - the stratified model that uses class weights performed consistently badly. \n",
    "    - The combination of over and undersampling improved recall (on the minority class), but hindered precision. \n",
    "    - So, we'll proceed in selecting between weighted classification and smoting on its own\n",
    "- We'll deal with the issue of selecting which model using cross validation (choice between smoting and class weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83        99\n",
      "           1       0.70      0.69      0.70        55\n",
      "\n",
      "    accuracy                           0.79       154\n",
      "   macro avg       0.77      0.76      0.77       154\n",
      "weighted avg       0.78      0.79      0.79       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score \n",
    "\n",
    "\n",
    "clf1 = RandomForestClassifier(class_weight = weights, random_state=42)\n",
    "##Ask me: why did we re-initialise the classifer, clf1??\n",
    "\n",
    "classifier_grid = GridSearchCV(estimator=clf1, param_grid ={}, cv=7)\n",
    "#### see how I left: param_grid empty, because we want to worry about hyperparmeter tuning later. \n",
    "#### param_grid is a mandatory argument, so I couldn't discard it alltogether. \n",
    "\n",
    "\n",
    "classifier_grid.fit(X_train, y_train)\n",
    "best_model1 = classifier_grid.best_estimator_\n",
    "y_pred= best_model1.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Your Task: </b> Do the same for clf2 using X_smoted and y_smoted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Your solution here #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's plot variable importance to see if there's any  difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "\n",
    "clf1_vector = best_model1.feature_importances_\n",
    "clf2_vector = best_model2.feature_importances_\n",
    "\n",
    "feature_names=X_original.columns\n",
    "\n",
    "# Set the ticks and ticklabels for all axes\n",
    "plt.setp(axes, xticks=range(len(clf1_vector)), xticklabels= clf1_vector)\n",
    "\n",
    "# Use the pyplot interface to change just one subplot...\n",
    "axes[0].bar(range(len(clf1_vector)), clf1_vector)\n",
    "axes[1].bar(range(len(clf2_vector)), clf2_vector)\n",
    "\n",
    "axes[0].set_xticklabels(feature_names, rotation='vertical' )\n",
    "axes[1].set_xticklabels(feature_names, rotation='vertical' )\n",
    "\n",
    "axes[0].set_title(' with Class Weights')\n",
    "axes[1].set_title(' With SMOTE')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It looks like using class weights provides a slightly more uniform distribution of variable importance\n",
    "- Let's see if selecting the most important variables makes a difference on performance\n",
    "- Let'see if we can further improve the model via feature selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sklearn has a nice subpackage called SelectFromModel\n",
    "- The code below shows you how to use it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glucose\n",
      "SkinThickness\n",
      "Insulin\n",
      "BMI\n",
      "DiabetesPedigreeFunction\n",
      "Age\n",
      " Classification report of RF using KNN Imputation, weighted classification AND feature selection  : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82        99\n",
      "           1       0.67      0.67      0.67        55\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.75      0.75      0.75       154\n",
      "weighted avg       0.77      0.77      0.77       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Create a selector object that will use the random forest classifier to identify\n",
    "# features that have an importance of more than 0.10 (guestimating from the importance plots)\n",
    "\n",
    "sfm = SelectFromModel(best_model1, threshold=0.07)\n",
    "\n",
    "# Train the selector\n",
    "sfm.fit(X_train, y_train)\n",
    "feature_names=X_original.columns\n",
    "\n",
    "# Print the names of the most important features\n",
    "for feature_list_index in sfm.get_support(indices=True):\n",
    "    print(feature_names[feature_list_index])\n",
    "    \n",
    "    \n",
    "# Create A Data Subset With Only The Most Important Features\n",
    "\n",
    "# Transform the data to create a new dataset containing only the most important features\n",
    "# Note: We have to apply the transform to both the training X and test X data.\n",
    "X_important_train = sfm.transform(X_train)\n",
    "X_important_test = sfm.transform(X_test)\n",
    "\n",
    "clf_important = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "\n",
    "# Train the new classifier on the new dataset containing the most important features\n",
    "clf_important.fit(X_important_train, y_train)\n",
    "\n",
    "y_pred = clf_important.predict(X_important_test)\n",
    "\n",
    "#Check performance\n",
    "print(\" Classification report of RF using KNN Imputation, weighted classification AND feature selection  : \")\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In my case, the performance went down. \n",
    "- This is directly related to the fact that the importance of the features are more or less uniformly distributed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's see if we can tune the hyperparameters of the best classifier so far (best_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score \n",
    "from pprint import pprint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': {0: 0.5, 1: 1.0},\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 42,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "print('Parameters currently in use:\\n')\n",
    "pprint(best_model1.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=7, estimator=RandomForestClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_features': [3, 5, 8],\n",
       "                         'min_samples_leaf': [1, 5, 20, 50],\n",
       "                         'n_estimators': [20, 60, 100, 200]})"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_grid = {\n",
    "            \"min_samples_leaf\": [1, 5, 20, 50],\n",
    "            'n_estimators': [20, 60, 100,200],\n",
    "             'max_features' : [3,5,8],\n",
    "            'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "classifier_grid = GridSearchCV(estimator=RandomForestClassifier(), param_grid=parameter_grid, cv=7)\n",
    "classifier_grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The best parameters found are: \n",
      "{'criterion': 'gini', 'max_features': 3, 'min_samples_leaf': 20, 'n_estimators': 20}\n"
     ]
    }
   ],
   "source": [
    "print(\" The best parameters found are: \")\n",
    "print(classifier_grid.best_params_)\n",
    "\n",
    "best_model = classifier_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82        99\n",
      "           1       0.68      0.65      0.67        55\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.75      0.74      0.74       154\n",
      "weighted avg       0.76      0.77      0.77       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Your Task: </b> \n",
    "- Let's also tune the Smoted model, just to be sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # # Your solution here # # # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Final Step </b>\n",
    "-After all of the experiments, we need to make sure that the best model is robust.\n",
    "-  Cross validation achieved the robustness. The fact that precision and recall are comparable to accuracy gives us some confidence. \n",
    "- But hyperparameter tuning didn't do so well, so we'll just revert to best_model1 (which is weighted classification using CV):\n",
    "- Establish the confidence in the final model using Repeated Stratified Cross Validation (stratify the folds and repeat the experiments of cross validation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.7543\n",
      "Mean Precision: 0.7345\n",
      "Mean Recall: 0.7101\n"
     ]
    }
   ],
   "source": [
    "# Define evaluation procedure (here we use Repeated Stratified K-Fold CV)\n",
    "cv_def=RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "scoring=['accuracy','precision_macro','recall_macro']\n",
    "\n",
    "final_scores = cross_validate(best_model1, X_original, y, scoring=scoring, cv=cv_def, n_jobs=-1)\n",
    "\n",
    "# summarize performance\n",
    "print('Mean Accuracy: %.4f' % np.mean(final_scores['test_accuracy']))\n",
    "print('Mean Precision: %.4f' % np.mean(final_scores['test_precision_macro']))\n",
    "print('Mean Recall: %.4f' % np.mean(final_scores['test_recall_macro']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"save\">Saving the model</h2>\n",
    "- sklearn provdies a nice feature- enables saving the model. \n",
    "- This is how you re-use your models without having to retrain!\n",
    "- Let's save our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'BestModel.sav'\n",
    "pickle.dump(best_model1, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You'll see your model int he current folder :) \n",
    "- You can load your model in future notebooks using pickle.load()\n",
    "- Read more here: https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
